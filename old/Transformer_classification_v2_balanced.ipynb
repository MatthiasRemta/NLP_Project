{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthiasRemta/NLP_Project/blob/main/Transformer_classification_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "O0aRjbR7dNRL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, EvalPrediction\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import accelerate\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import string\n",
        "import numpy as np\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BTaKIqSxviQY"
      },
      "outputs": [],
      "source": [
        "#pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WPxpfC-FvwYS"
      },
      "outputs": [],
      "source": [
        "#pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YVzW0PR0whN6"
      },
      "outputs": [],
      "source": [
        "#pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIBhXMXnxuSq",
        "outputId": "ac768a22-518f-4f54-b6ad-066f2733675d"
      },
      "outputs": [],
      "source": [
        "#!wget https://raw.githubusercontent.com/MatthiasRemta/NLP_Project/main/Data/MovieSummaries/plots_genres_reduced_to_60.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baPSDnOOdNRf"
      },
      "source": [
        "The following notebook is based on https://huggingface.co/docs/transformers/tasks/sequence_classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "O0TrIOnYdNRp"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "#df_raw = pd.read_pickle('plots_genres_reduced_to_60.pkl')\n",
        "df_raw = pd.read_pickle('Data\\MovieSummaries\\plots_genres_balanced.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i9qHoRc8c4b_"
      },
      "outputs": [],
      "source": [
        "# Specify mappings (id -> label) and (label -> id)\n",
        "genres =[]\n",
        "for row in df_raw['genre']:\n",
        "  for genre in row:\n",
        "    genres.append(genre)\n",
        "\n",
        "unique_genres = []\n",
        "\n",
        "for item in genres:\n",
        "    if item not in unique_genres:\n",
        "        unique_genres.append(item)\n",
        "\n",
        "label2id = dict([(tuple[1], tuple[0]) for tuple in enumerate(unique_genres)])\n",
        "id2label = dict([(label2id[key], key) for key in label2id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh5D0rFrh_lz",
        "outputId": "d9496c6d-86d8-4d90-c895-34efd50d2958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'cult': 0, 'horror': 1, 'short': 2, 'biography': 3, 'documentary': 4, 'thriller': 5, 'melodrama': 6, 'adventure': 7, 'supernatural': 8, 'mystery': 9, 'drama': 10, 'suspense': 11, 'action': 12, 'indie': 13, 'childrensfamily': 14, 'fantasy': 15, 'war': 16, 'childrens': 17, 'psychological thriller': 18, 'crime': 19, 'romance': 20, 'family': 21, 'actionadventure': 22, 'chinese': 23, 'comedy': 24, 'animation': 25, 'period piece': 26, 'biopic feature': 27, 'biographical': 28, 'silent': 29, 'comedydrama': 30, 'adaptation': 31, 'science fiction': 32, 'martial arts': 33, 'lgbt': 34, 'japanese': 35, 'teen': 36, 'creature': 37, 'slasher': 38, 'political': 39, 'television': 40, 'musical': 41, 'history': 42, 'coming of age': 43, 'noir': 44, 'sports': 45, 'bmovie': 46, 'blackandwhite': 47, 'spy': 48, 'music': 49, 'slapstick': 50, 'bollywood': 51, 'art': 52, 'western': 53, 'ensemble': 54, 'satire': 55, 'parody': 56}\n",
            "{0: 'cult', 1: 'horror', 2: 'short', 3: 'biography', 4: 'documentary', 5: 'thriller', 6: 'melodrama', 7: 'adventure', 8: 'supernatural', 9: 'mystery', 10: 'drama', 11: 'suspense', 12: 'action', 13: 'indie', 14: 'childrensfamily', 15: 'fantasy', 16: 'war', 17: 'childrens', 18: 'psychological thriller', 19: 'crime', 20: 'romance', 21: 'family', 22: 'actionadventure', 23: 'chinese', 24: 'comedy', 25: 'animation', 26: 'period piece', 27: 'biopic feature', 28: 'biographical', 29: 'silent', 30: 'comedydrama', 31: 'adaptation', 32: 'science fiction', 33: 'martial arts', 34: 'lgbt', 35: 'japanese', 36: 'teen', 37: 'creature', 38: 'slasher', 39: 'political', 40: 'television', 41: 'musical', 42: 'history', 43: 'coming of age', 44: 'noir', 45: 'sports', 46: 'bmovie', 47: 'blackandwhite', 48: 'spy', 49: 'music', 50: 'slapstick', 51: 'bollywood', 52: 'art', 53: 'western', 54: 'ensemble', 55: 'satire', 56: 'parody'}\n"
          ]
        }
      ],
      "source": [
        "# look at the mappings\n",
        "print(label2id)\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jJbrvHOsdHKF"
      },
      "outputs": [],
      "source": [
        "# encode the labels as vector\n",
        "def labels_to_binary(labels, unique_labels):\n",
        "    binary_vector = np.zeros(len(unique_labels))\n",
        "    for label in labels:\n",
        "        binary_vector[unique_labels[label]] = 1\n",
        "    return binary_vector\n",
        "\n",
        "\n",
        "labels = []\n",
        "for ele in df_raw['genre']:\n",
        "    labels.append(labels_to_binary(ele, label2id))\n",
        "\n",
        "df_raw['labels'] = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fJMyQwxzcuop"
      },
      "outputs": [],
      "source": [
        "# convert to dataset\n",
        "df_complete = Dataset.from_pandas(df_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ppl1XevzZeP"
      },
      "source": [
        "# Neuer Abschnitt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBLur6tMdNRt",
        "outputId": "18da8fcc-6cd2-417b-e895-d2ccd8fe0585"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c07a535043c24d07a8e2d406dc337d4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Felix\\.conda\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Felix\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f420a345ed9c4e05b0d7cab251f1e716",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42c67dab9b89435ebc68589332a46f1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd52dbab9ff042f7b7e131be6eb220fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# define tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ptXoJaxidNRy"
      },
      "outputs": [],
      "source": [
        "# function for tokenization\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=tokenizer.model_max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0e00dc15ab1e4053b1660c17c61806fa",
            "0c0101ff8f4c46dfadf6397ebd3fd62d",
            "c27c89eca92f4626b95f6a8e0576a43c",
            "fb12479507ab49229b75376269b2d962",
            "0f20c938b9474745aaa38e87008bb233",
            "695f7086bc4d45f08778d743c8ee0302",
            "98d1b31ddb704e4eb25f7ab5c1e51abe",
            "585bc08e824b47018d400e20f2a8375a",
            "d92cc18191f24ba8bebf96bcd9636f90",
            "b69b3e26f3dd4fed9df3c6d642e89e2b",
            "a6dd8a9601424a1894134b419997aa14"
          ]
        },
        "id": "HUkLoZWEdNR1",
        "outputId": "e8e8fcc0-2f66-4c42-e03f-1f1954a27654"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcd0a5e1aef94836bb5a3557a469f3ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/19494 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# preprocess the plot summaries\n",
        "df_tokenized = df_complete.map(preprocess_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6gMJ-6uMdNR9"
      },
      "outputs": [],
      "source": [
        "# Create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "i8qwNLjDdNSB"
      },
      "outputs": [],
      "source": [
        "# define metrics\n",
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    # return as dictionary\n",
        "    metrics = {'f1': f1_micro_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'accuracy': accuracy}\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions,\n",
        "            tuple) else p.predictions\n",
        "    result = multi_label_metrics(\n",
        "        predictions=preds,\n",
        "        labels=p.label_ids)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aPhj1OkipJwJ"
      },
      "outputs": [],
      "source": [
        "# Create train/test split\n",
        "df_tokenized = df_tokenized.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW6Nd_whdNSI",
        "outputId": "e775dae6-88b3-4181-dd82-ecc1bcc8b7fc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "111ea33b4e8040549c3ebdc8608e5e72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    problem_type='multi_label_classification'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ3XBChV8aA_",
        "outputId": "0767da0b-a426-4a8a-e000-848b172b5062"
      },
      "outputs": [],
      "source": [
        "#pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m977aB9whl_h",
        "outputId": "503cc46f-8a07-4ffd-fd20-3db27fd3c758"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check whether cuda is available\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('4.32.1', '0.23.0')"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformers.__version__, accelerate.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "soBf9qztdNSL",
        "outputId": "172e1b47-91c4-46b1-8045-ebbe8a46b664"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Felix\\Dropbox\\Fh\\WS23\\NLP\\NLP_Project\\Transformer_classification_v2_balanced.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# ToDo: Specify parameters correctly\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Train/Test split?\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     output_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m2e-5\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     per_device_eval_batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     save_strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     load_best_model_at_end\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     push_to_hub\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felix/Dropbox/Fh/WS23/NLP/NLP_Project/Transformer_classification_v2_balanced.ipynb#X31sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
            "File \u001b[1;32m<string>:114\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\Felix\\.conda\\envs\\nlp\\lib\\site-packages\\transformers\\training_args.py:1400\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1394\u001b[0m     \u001b[39mif\u001b[39;00m version\u001b[39m.\u001b[39mparse(version\u001b[39m.\u001b[39mparse(torch\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mbase_version) \u001b[39m==\u001b[39m version\u001b[39m.\u001b[39mparse(\u001b[39m\"\u001b[39m\u001b[39m2.0.0\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16:\n\u001b[0;32m   1395\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1397\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1398\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1399\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[1;32m-> 1400\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1401\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1402\u001b[0m     \u001b[39mand\u001b[39;00m (get_xla_device_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1403\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16_full_eval)\n\u001b[0;32m   1404\u001b[0m ):\n\u001b[0;32m   1405\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1406\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1407\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m (`--fp16_full_eval`) can only be used on CUDA or NPU devices.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1408\u001b[0m     )\n\u001b[0;32m   1410\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1411\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1412\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16_full_eval)\n\u001b[0;32m   1418\u001b[0m ):\n",
            "File \u001b[1;32mc:\\Users\\Felix\\.conda\\envs\\nlp\\lib\\site-packages\\transformers\\training_args.py:1857\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1853\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1854\u001b[0m \u001b[39mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m requires_backends(\u001b[39mself\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m-> 1857\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_devices\n",
            "File \u001b[1;32mc:\\Users\\Felix\\.conda\\envs\\nlp\\lib\\site-packages\\transformers\\utils\\generic.py:54\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     52\u001b[0m cached \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, attr, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m cached \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfget(obj)\n\u001b[0;32m     55\u001b[0m     \u001b[39msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m cached\n",
            "File \u001b[1;32mc:\\Users\\Felix\\.conda\\envs\\nlp\\lib\\site-packages\\transformers\\training_args.py:1772\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   1771\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_accelerate_available(min_version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m0.20.1\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1772\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   1773\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1774\u001b[0m         )\n\u001b[0;32m   1775\u001b[0m     AcceleratorState\u001b[39m.\u001b[39m_reset_state(reset_partial_state\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1776\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistributed_state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
          ]
        }
      ],
      "source": [
        "# ToDo: Specify parameters correctly\n",
        "# Train/Test split?\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=df_tokenized[\"train\"],\n",
        "    eval_dataset=df_tokenized[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c0101ff8f4c46dfadf6397ebd3fd62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_695f7086bc4d45f08778d743c8ee0302",
            "placeholder": "​",
            "style": "IPY_MODEL_98d1b31ddb704e4eb25f7ab5c1e51abe",
            "value": "Map: 100%"
          }
        },
        "0e00dc15ab1e4053b1660c17c61806fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c0101ff8f4c46dfadf6397ebd3fd62d",
              "IPY_MODEL_c27c89eca92f4626b95f6a8e0576a43c",
              "IPY_MODEL_fb12479507ab49229b75376269b2d962"
            ],
            "layout": "IPY_MODEL_0f20c938b9474745aaa38e87008bb233"
          }
        },
        "0f20c938b9474745aaa38e87008bb233": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "585bc08e824b47018d400e20f2a8375a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "695f7086bc4d45f08778d743c8ee0302": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d1b31ddb704e4eb25f7ab5c1e51abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6dd8a9601424a1894134b419997aa14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b69b3e26f3dd4fed9df3c6d642e89e2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c27c89eca92f4626b95f6a8e0576a43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_585bc08e824b47018d400e20f2a8375a",
            "max": 41549,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d92cc18191f24ba8bebf96bcd9636f90",
            "value": 41549
          }
        },
        "d92cc18191f24ba8bebf96bcd9636f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb12479507ab49229b75376269b2d962": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b69b3e26f3dd4fed9df3c6d642e89e2b",
            "placeholder": "​",
            "style": "IPY_MODEL_a6dd8a9601424a1894134b419997aa14",
            "value": " 41549/41549 [01:09&lt;00:00, 1019.72 examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
